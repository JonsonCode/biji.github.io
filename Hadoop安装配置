设置SSH无密码登录
安装ssh

sudo apt-get install ssh
 
安装rsync

sudo apt-get install rsync

产生ssh key 进行后续身份验证

ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa

查看ssh key : ll ~/.ssh

将产生的key放置到许可文件中

cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys

下载安装Hadoop
https://archive.apache.org/dist/hadoop/common

Wget https://archive.apache.org/dist/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz

sudo tar -zxvf Hadoop-2.6.0.tar.gz
sudo mv hadoop-2.6.0 /usr/local/hadoop
ll /usr/local/hadoop

设置Hadoop环境

sudo gedit ~/.bashrc

#java1.8
export JAVA_HOME=/usr/lib/jvm/java1.8(根据自己安装路径)
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
#hadoop
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-DJava.library.path=$HADOOP_HOME/lib"
export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native:$JAVA_LIBRARY_PATH

source ~/.bashrc

Hadoop	配置设置文件

sudo gedit /usr/local/hadoop/etc/hadoop/hadoop-env.sh
# The java implementation to use.
export JAVA_HOME=/usr/lib/jvm/java1.8

sudo gedit /usr/local/hadoop/etc/hadoop/core-site.xml
------------------------------------------------------
<property>
   <name>fs.default.name</name>
   <value>hdfs://localhost:9000</value>
</property>
------------------------------------------------------
sudo gedit /usr/local/hadoop/etc/hadoop/yarn-site.xml
-------------------------------------------------------------------
<property>
   <name>yarn.nodemanager.aux-services</name>
   <value>mapreduce_shuffle</value>
</property>
<property>
   <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
   <value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
--------------------------------------------------------------------

sudo cp /usr/local/hadoop/etc/hadoop/mapred-site.xml.template /usr/local/hadoop/etc/hadoop/mapred-site.xml

sudo gedit /usr/local.hadoop/etc/hadoop/mapred-site.xml
---------------------------------------------
<property>
   <name>mapreduce.framework.name</name>
   <value>yarn</value>
</property>
----------------------------------------------

sudo gedit /usr/local/hadoop/etc/hadoop/hdfs-site.xml
----------------------------------------------------------------
<property>
    <name>dfs.replication</name>
    <value>3</value>
</property>
<property>
    <name>dfs.namenode.name.dir</name>
    <value>file:/usr/local/hadoop/hadoop_data/hdfs/namenode</value>
</property>
<property>
    <name>dfs.datanode.data.dir</name>
    <value>file:/usr/local/hadoop/hadoop_data/hdfs/datanode</value>
</property>
---------------------------------------------------------------------

sudo mkdir -p /usr/local/hadoop/hadoop_data/hdfs/namenode

sudo mkdir -p /usr/local/hadoop/hadoop_data/hdfs/datanode

sudo chown w:w -R /usr/local/hadoop

hadoop namenode -format

start-dfs.sh
start-yarn.sh
jps

http://localhost:8088/

复制节点

将 hadoop-2.7.4 文件夹重打包后复制到其他子节点

cd /home/hadoop/

sudo tar zcvf hadoop.tar.gz hadoop-2.7.4
scp hadoop.tar.gz hduser@data:/home/hduser/

在其他子节点 解压

tar -zxvf hadoop.tar.gz
